### References
[Ref 1. 세종대학교 github](https://github.com/sejongresearch/2024.DeepLearning)
# Personal Study
---
##### Machine Learning vs. Deep Learning
[Ref 2. 딥 러닝과 머신 러닝의 비교](https://www.zendesk.kr/blog/machine-learning-and-deep-learning/)
###### 머신러닝 PipeLine
1. **데이터를 수집**
2. **데이터를 전처리**
3. **훈련 데이터, 처리 검증데이터 분리**
4. **알고리즘 선택**
5. **실행**
6. **결과 도출**
### 1. 데이터 수집

문제를 해결하기 위한 가장 첫 단계는 **적절한 데이터를 확보**하는 것입니다. 이는 프로젝트의 성패를 좌우하는 중요한 단계로, 다양한 방법을 통해 데이터를 수집합니다.

- **내부 데이터**: 기존 시스템에서 이미 수집한 데이터나 로그, 고객 행동 데이터, 거래 내역 등을 활용합니다.
- **외부 데이터**: 웹 스크래핑을 통해 온라인 데이터베이스나 공개 API를 사용해 추가 데이터를 수집할 수 있습니다.
- **공공 데이터 및 데이터셋**: Kaggle, UCI ML 리포지토리 등에서 공개된 데이터를 사용할 수도 있습니다.

데이터를 수집할 때는 문제가 무엇인지, 예측하고자 하는 목적이 무엇인지에 맞춰 데이터를 적절히 수집하고 저장해야 합니다.

### 2. 데이터 전처리

수집한 데이터는 대부분 바로 사용할 수 없으므로 **모델 학습에 적합한 상태로 가공**해야 합니다. 전처리는 모델이 더 효과적으로 학습할 수 있도록 데이터를 정리하는 과정입니다.

- **결측치 처리**: 데이터에 누락된 값이 있을 경우, 이를 보정하거나 제거해야 합니다. 보통 평균, 중앙값으로 대체하거나, 특정 행 전체를 삭제할 수 있습니다.
- **이상치 탐지**: 데이터의 범위를 벗어나거나 비정상적인 값은 모델 성능을 저하시킬 수 있습니다. 이런 값은 도메인 지식에 따라 수정하거나 제거합니다.
- **데이터 정규화 및 표준화**: 데이터 값의 범위가 너무 크면 학습에 불리할 수 있습니다. 표준화(평균과 표준편차로 스케일 조정)나 정규화(데이터 값을 0에서 1 사이로 변환)를 통해 모델이 학습하기 쉽게 조정합니다.
- **레이블 인코딩**: 범주형 데이터를 숫자로 변환해야 합니다. 예를 들어, ‘남성’은 1로, ‘여성’은 0으로 변환하는 식입니다. 이는 텍스트 데이터를 모델이 이해할 수 있도록 하는 과정입니다.

이 외에도, 텍스트 분석에서는 **불용어 제거**, **어간 추출** 등의 전처리, 이미지 처리에서는 **이미지 크기 조정** 및 **필터링** 같은 다양한 전처리 방법이 사용됩니다.

### 3. 훈련 데이터와 검증 데이터 분리

모델의 성능을 정확하게 평가하기 위해, 수집된 데이터를 **훈련 데이터**와 **검증 데이터(또는 테스트 데이터)**로 나눕니다. 훈련 데이터는 모델 학습에 사용하고, 검증 데이터는 학습된 모델이 새로운 데이터에서도 잘 일반화되었는지 평가하기 위해 사용됩니다.

- **비율 설정**: 일반적으로 데이터의 70~~80%는 훈련 데이터로, 20~~30%는 검증 데이터로 사용합니다.
- **교차 검증**: 데이터셋을 여러 번 나누어 학습하고 평가해, 모델의 일반화 성능을 높입니다. K-폴드 교차 검증이 대표적입니다.

이 과정에서 검증 데이터는 학습 과정에 참여하지 않기 때문에 모델이 과적합(overfitting)되지 않고 일반화 능력을 갖출 수 있도록 돕습니다.

### 4. 알고리즘 선택

데이터의 특성과 문제의 성격에 맞는 **알고리즘을 선택**합니다. 이 단계에서는 문제의 유형에 따라 적합한 알고리즘을 선택하는 것이 중요합니다.

- **회귀 분석**: 숫자 예측 문제에 적합합니다. 예를 들어, 주택 가격 예측에서는 선형 회귀나 다중 회귀 모델을 사용할 수 있습니다.
- **분류 알고리즘**: 카테고리를 예측하는 문제에는 로지스틱 회귀, 의사결정 나무, 서포트 벡터 머신(SVM) 등이 사용됩니다.
- **신경망 및 딥러닝 모델**: 이미지 인식에는 합성곱 신경망(CNN), 텍스트 분석에는 순환 신경망(RNN)이나 트랜스포머 등이 유리합니다.

문제에 맞는 알고리즘을 선택해야만 모델이 데이터의 패턴을 더 잘 학습하고 정확하게 예측할 수 있습니다.

### 5. 모델 학습 및 최적화

선택한 알고리즘을 **훈련 데이터에 적용하여 학습**합니다. 이 과정에서 **하이퍼파라미터 튜닝**을 통해 모델의 성능을 최적화합니다. 딥러닝의 경우 연산량이 크기 때문에 **GPU**나 **TPU** 같은 고성능 컴퓨팅 자원을 사용해 학습 속도를 높일 수 있습니다.

- **하이퍼파라미터 튜닝**: 학습률, 배치 크기 등 모델의 성능에 영향을 미치는 요소들을 최적화합니다. Grid Search나 Random Search, Bayesian Optimization과 같은 방법으로 최적의 하이퍼파라미터를 찾습니다.
- **조기 종료**: 학습이 진행될수록 훈련 데이터에서는 성능이 높아지지만 검증 데이터에서 성능이 떨어질 수 있습니다. 이를 방지하기 위해 일정 기준에서 학습을 중단해 과적합을 방지합니다.

### 6. 결과 도출 및 성능 평가

모델 학습이 완료되면, **검증 데이터로 최종 평가**하여 예측의 성능을 확인합니다. 주요 평가 지표는 다음과 같습니다.

- **정확도(Accuracy)**: 전체 예측 중 맞힌 예측의 비율로, 분류 문제에서 가장 일반적인 평가 척도입니다.
- **정밀도(Precision)와 재현율(Recall)**: 특정 클래스의 예측 성능을 측정하는 데 유용합니다. 예를 들어, 의료 데이터에서는 False Positive를 최소화하는 것이 중요할 때 정밀도를 높게 설정합니다.
- **F1-score**: 정밀도와 재현율의 조화 평균으로, 두 지표가 균형을 이룬 모델을 만들 때 유용합니다.
- **MSE, MAE**: 회귀 모델의 평가에 많이 사용되며, 모델이 예측한 값과 실제 값의 차이를 측정합니다.

최종 결과를 분석한 후, 모델이 실제 문제에 적합하다면 배포할 준비를 합니다. 필요 시 추가적인 **모델 개선**과 **성능 튜닝**을 반복하며, 결과에 따라 새로운 데이터나 추가적인 학습을 통해 모델을 점진적으로 발전시킬 수 있습니다.

이와 같은 반복적이고 체계적인 과정이 머신러닝 및 딥러닝 모델의 성공적인 구축과 실사용에서의 성능을 보장합니다.
# Lecture Study
---
[Ref 3. 인공뉴런 관련](https://www.mql5.com/ko/articles/5486)
### 인공 신경망(Artificial Neural Networks)
- **`연결주의 인공지능`** 
##### 구성
- `수상돌기(dendrite)` - `신경세포체(soma)` - `축삭돌기(axon)` - `시냅스(synapse)`
	- `수상돌기(denite)` : **입력**, _연결 가중치를 학습_
	- `신경세포체(soma)` : **연산 수행**, _노드_
	- `축삭돌기(axon)` : **출력**, _처리한 정보를 뉴런에게 전달_
- **1957년, Frank Rosenblatt : 퍼셉트론(Perceptron) 학습 모델 제시**
	- *1969, 단층 퍼셉트론은 배타적 논리합(XOR)과 같은 간단한 문제도 해결 못함*
	- **1974, 다층 퍼셉트론 구조의 학습 방법이 발표 -> `역전파(backpropagation) 알고리즘`**
==단층, 다층, 가중치 ==
- **`심층 신경망(deep neural network)`**
	- 많은 수의 층으로 구성하면 더욱 높은 차원의 표현이 가능
- `**딥러닝(deep learning)**`
	- 심층 신경망을 학습하기 위해 활용되는 기계학습 알고리즘
	- 학습 성능을 제한하는 제반 문제의 개선이 필요
		- *(부족한 학습 데이터, 불안정한 경사, 과적합, 방대한 계산량)*
### 신경망의 기본 구조
##### 인공 뉴런
![[artificialneural.gif]]
**연산 과정**
1. `입력 값`과 `가중치`를 곱한다.
2. `입력 값 * 가중치` 모두 더한다. 이때, `편향치`도 함께 더한다.
3. `∑(입력 값 * 가중치) + 편향치`를 `활성함수`에 넣는다.
4. 결과 도출

- **활성함수(activation function)**
	- 일반적으로 비선형 특징을 갖는 함수 사용
	- u의 값이 0보다 작으면 출력 억제, 0보다 크면 출력
- **가중치(바이어스, bias)**
	- 뉴런이 활성화 되는 레벨을 조정